{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and saving a randomly generated task dataset "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 10:41:30.453247: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from cognitive import constants as const\n",
    "from cognitive.auto_task import auto_task_util as auto_task\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Initialization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we initialize the parameters which control the random task generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stimuli Directory:  ../data/MULTIF_5_stim/MULTIF_5_stim\n",
      "OrderedDict([((0, 0), [(0.0, 0.5), (0.0, 0.5)]), ((0, 1), [(0.0, 0.5), (0.5, 1.0)]), ((1, 0), [(0.5, 1.0), (0.0, 0.5)]), ((1, 1), [(0.5, 1.0), (0.5, 1.0)])])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_op = 5 # the depth of the task graph\n",
    "max_depth = 5 # the maximum number of operators in the task\n",
    "max_switch = 1 # the maximum number of switch operators in the task graph\n",
    "select_limit = True\n",
    "switch_threshold = 0.3 # chance to add switch operator \n",
    "boolean_ops = [\"IsSame\", \"And\"] # possible boolean operators for the task\n",
    "output_dir = '../datasets/trials' # the output directory\n",
    "stim_dir = '../data/MULTIF_5_stim/MULTIF_5_stim' # stimulus set\n",
    "n_tasks = 10 # number of tasks to be generated\n",
    "\n",
    "const.DATA = const.Data(dir_path=stim_dir)\n",
    "op_dict = auto_task.op_dict\n",
    "\n",
    "# Create the output directory\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "os.makedirs(output_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generate the random tasks and write them to the output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_tasks):\n",
    "    task_graph, task = auto_task.task_generator(max_switch,\n",
    "                                        switch_threshold,\n",
    "                                        max_op,\n",
    "                                        max_depth,\n",
    "                                        select_limit)\n",
    "\n",
    "    fp = os.path.join(output_dir, 'trial' + str(i))\n",
    "    auto_task.write_trial_instance(task[1], fp, 224, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "task_graph, task = auto_task.task_generator(max_switch,\n",
    "                                    switch_threshold,\n",
    "                                    max_op,\n",
    "                                    max_depth,\n",
    "                                    select_limit)   \n",
    "\n",
    "\n",
    "\n",
    "# G = task.to_graph()\n",
    "# task[1].draw_graph('rand_task_.png', task_graph)\n",
    "G, _, _ = task_graph\n",
    "G = G.reverse()\n",
    "\n",
    "A = nx.nx_agraph.to_agraph(G)\n",
    "A.draw(os.path.join(\"operator_graph.png\"), prog=\"dot\")\n",
    "\n",
    "fp = os.path.join(output_dir, 'trial')\n",
    "auto_task.write_trial_instance(task[1], fp, 224, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.comp_loc_task.to_json('comp_loc_task_.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bashlab_cogenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
