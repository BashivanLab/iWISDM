{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and saving a single task dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 00:53:43.846914: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-14 00:53:43.847041: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-14 00:53:43.847129: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-14 00:53:43.853081: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-14 00:53:44.978265: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from cognitive import constants as const\n",
    "from cognitive.auto_task.auto_task_util import write_trial_instance\n",
    "from cognitive.task_bank import CompareLocTemporal, CompareCategoryTemporal, SequentialCategoryMatch, SequentialLocationMatch\n",
    "import os\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we define the constants for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '../datasets/val_big_2' # the output directory\n",
    "stim_dir = '../data/new_shapenet_val' #../data/MULTIF_5_stim/MULTIF_5_stim' # stimulus set\n",
    "n_tasks = 3000 # number of tasks to be generated\n",
    "const.DATA = const.Data(dir_path=stim_dir)#, max_memory=3)\n",
    "\n",
    "# Create the output directory\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generate the tasks and write them to the output directory\n",
    "- (remember to specify 'train' parameter of write function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (56,56,3) into shape (56,0,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/lucasgomez/Desktop/Neuro/Bashvian/COGEnv/COG_v3_shapenet-main/tutorials/task_dataset_gen.ipynb Cell 9\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lucasgomez/Desktop/Neuro/Bashvian/COGEnv/COG_v3_shapenet-main/tutorials/task_dataset_gen.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Write trial to disk\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lucasgomez/Desktop/Neuro/Bashvian/COGEnv/COG_v3_shapenet-main/tutorials/task_dataset_gen.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m fp \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_dir, \u001b[39m'\u001b[39m\u001b[39mtrial\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(i))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lucasgomez/Desktop/Neuro/Bashvian/COGEnv/COG_v3_shapenet-main/tutorials/task_dataset_gen.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m write_trial_instance(task, fp, \u001b[39m224\u001b[39;49m, \u001b[39mTrue\u001b[39;49;00m, train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Desktop/Neuro/Bashvian/COGEnv/COG_v3_shapenet-main/tutorials/../cognitive/auto_task/auto_task_util.py:339\u001b[0m, in \u001b[0;36mwrite_trial_instance\u001b[0;34m(task, write_fp, img_size, fixation_cue, train)\u001b[0m\n\u001b[1;32m    337\u001b[0m compo_info \u001b[39m=\u001b[39m ig\u001b[39m.\u001b[39mTaskInfoCompo(task, frame_info)\n\u001b[1;32m    338\u001b[0m objset \u001b[39m=\u001b[39m compo_info\u001b[39m.\u001b[39mframe_info\u001b[39m.\u001b[39mobjset\n\u001b[0;32m--> 339\u001b[0m \u001b[39mfor\u001b[39;00m i, (epoch, frame) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(sg\u001b[39m.\u001b[39;49mrender(objset, img_size, train\u001b[39m=\u001b[39;49mtrain), compo_info\u001b[39m.\u001b[39mframe_info)):\n\u001b[1;32m    340\u001b[0m     \u001b[39m# add cross in the center of the image\u001b[39;00m\n\u001b[1;32m    341\u001b[0m     \u001b[39mif\u001b[39;00m fixation_cue:\n\u001b[1;32m    342\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mending\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m description \u001b[39mfor\u001b[39;00m description \u001b[39min\u001b[39;00m frame\u001b[39m.\u001b[39mdescription):\n",
      "File \u001b[0;32m~/Desktop/Neuro/Bashvian/COGEnv/COG_v3_shapenet-main/tutorials/../cognitive/stim_generator.py:941\u001b[0m, in \u001b[0;36mrender\u001b[0;34m(objsets, img_size, save_name, train)\u001b[0m\n\u001b[1;32m    939\u001b[0m         subset \u001b[39m=\u001b[39m objset\u001b[39m.\u001b[39mselect_now(epoch_now)\n\u001b[1;32m    940\u001b[0m         \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m subset:\n\u001b[0;32m--> 941\u001b[0m             render_obj(canvas, obj, img_size, train\u001b[39m=\u001b[39;49mtrain)\n\u001b[1;32m    942\u001b[0m         i_frame \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    944\u001b[0m \u001b[39mif\u001b[39;00m save_name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Neuro/Bashvian/COGEnv/COG_v3_shapenet-main/tutorials/../cognitive/stim_generator.py:855\u001b[0m, in \u001b[0;36mrender_obj\u001b[0;34m(canvas, obj, img_size, train)\u001b[0m\n\u001b[1;32m    853\u001b[0m     render_static_obj(canvas, obj, img_size, train\u001b[39m=\u001b[39mtrain)\n\u001b[1;32m    854\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 855\u001b[0m     render_static_obj(canvas, obj\u001b[39m.\u001b[39;49mto_static()[\u001b[39m0\u001b[39;49m], img_size, train\u001b[39m=\u001b[39;49mtrain)\n",
      "File \u001b[0;32m~/Desktop/Neuro/Bashvian/COGEnv/COG_v3_shapenet-main/tutorials/../cognitive/stim_generator.py:840\u001b[0m, in \u001b[0;36mrender_static_obj\u001b[0;34m(canvas, obj, img_size, train)\u001b[0m\n\u001b[1;32m    838\u001b[0m shape_net_obj \u001b[39m=\u001b[39m const\u001b[39m.\u001b[39mDATA\u001b[39m.\u001b[39mget_shapenet_object(obj, [radius \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, radius \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m], train\u001b[39m=\u001b[39mtrain)\n\u001b[1;32m    839\u001b[0m \u001b[39massert\u001b[39;00m shape_net_obj\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m (x_end \u001b[39m-\u001b[39m x_offset, y_end \u001b[39m-\u001b[39m y_offset)\n\u001b[0;32m--> 840\u001b[0m canvas[x_offset:x_end, y_offset:y_end] \u001b[39m=\u001b[39m shape_net_obj\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (56,56,3) into shape (56,0,3)"
     ]
    }
   ],
   "source": [
    "for i in range(n_tasks):\n",
    "\n",
    "    # Choose a task class (see task_bank or make your own see individual_task_gen.ipynb)\n",
    "    task = CompareCategoryTemporal(whens=['last2','last0'])\n",
    "\n",
    "    # Write trial to disk\n",
    "    fp = os.path.join(output_dir, 'trial' + str(i))\n",
    "    write_trial_instance(task, fp, 224, True, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bashlab_cogenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
