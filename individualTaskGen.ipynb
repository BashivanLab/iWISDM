{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcognitive\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask_bank\u001b[39;00m \u001b[39mimport\u001b[39;00m SequentialCategoryMatch\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcognitive\u001b[39;00m \u001b[39mimport\u001b[39;00m stim_generator \u001b[39mas\u001b[39;00m sg\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcognitive\u001b[39;00m \u001b[39mimport\u001b[39;00m task_generator \u001b[39mas\u001b[39;00m tg\n",
      "File \u001b[0;32m~/Desktop/Neuro/Bashvian/COGEnv/COG_v3_shapenet-main/cognitive/task_bank.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m OrderedDict\n\u001b[1;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcognitive\u001b[39;00m \u001b[39mimport\u001b[39;00m stim_generator \u001b[39mas\u001b[39;00m sg\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcognitive\u001b[39;00m \u001b[39mimport\u001b[39;00m task_generator \u001b[39mas\u001b[39;00m tg\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from cognitive.task_bank import SequentialCategoryMatch\n",
    "from cognitive import stim_generator as sg\n",
    "from cognitive import task_generator as tg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class SequentialCategoryMatch(TemporalTask):\n",
    "    def __init__(self, whens=None, first_shareable=None, n_frames=1):\n",
    "        super(SequentialCategoryMatch, self).__init__(whens=whens, first_shareable=first_shareable)\n",
    "        total_frames = n_frames * 2 + random.randint(0, const.MAX_MEMORY - (n_frames * 2) + 1)\n",
    "\n",
    "        sample_objs = [tg.Select(when=f'last{total_frames - i - 1}') for i in range(n_frames)]\n",
    "        response_objs = [tg.Select(when=f'last{i}') for i in range(n_frames)]\n",
    "        sample_cats = [tg.GetCategory(obj) for obj in sample_objs]\n",
    "        response_cats = [tg.GetCategory(obj) for obj in response_objs]\n",
    "        is_sames = [tg.IsSame(sample, response) for sample, response in zip(sample_cats, response_cats)]\n",
    "        if n_frames == 1:\n",
    "            self._operator = is_sames[0]\n",
    "        else:\n",
    "            ands = tg.And(is_sames[0], is_sames[1])\n",
    "            for is_same1, is_same2 in zip(is_sames[2::2], is_sames[3::2]):\n",
    "                ands = tg.And(tg.And(is_same1, is_same2), ands)\n",
    "            self._operator = ands\n",
    "        self.n_frames = total_frames\n",
    "\n",
    "    @property\n",
    "    def instance_size(self):\n",
    "        return sg.n_sample_shape(2) * (sg.n_random_when()) ** 2\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_memory = 12\n",
    "max_distractors=0\n",
    "trials_per_family=1\n",
    "output_dir='./data'\n",
    "stim_dir='./data/MULTIF_5_stim'\n",
    "random_families=True\n",
    "families=['CompareLoc']\n",
    "composition=3\n",
    "temporal_switch=0\n",
    "img_size=224\n",
    "training =1.0\n",
    "validation = 0\n",
    "nback = 1\n",
    "nback_length = 6\n",
    "seq_length = 6\n",
    "seq_reverse = False\n",
    "fix_delay = False\n",
    "fixation_cue = True\n",
    "\n",
    "\n",
    "whens = [f'last{nback}', 'last0']\n",
    "const.DATA = const.Data(args.stim_dir)\n",
    "assert all('Compare' in family for family in args.families)\n",
    "composition = args.nback_length - args.nback + 1\n",
    "\n",
    "examples_per_family=trials_per_family\n",
    "output_dir=output_dir\n",
    "composition=composition\n",
    "img_size=img_size\n",
    "random_families=random_families\n",
    "families=families\n",
    "train=training\n",
    "validation=validation\n",
    "fixation_cue=fixation_cue\n",
    "max_memory=max_memory\n",
    "max_distractors=max_distractors\n",
    "whens=whens\n",
    "first_shareable=1\n",
    "temporal_switch=temporal_switch\n",
    "\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CompareLocTemporal\n",
    "\n",
    "def generate_temporal_example(, task_family,\n",
    "                              whens=None, first_shareable=None, *args, **kwargs):\n",
    "    # max_memory\n",
    "\n",
    "\n",
    "    task = CompareLocTemporal(task_family, whens, first_shareable)\n",
    "    assert isinstance(task, tg.TemporalTask)\n",
    "\n",
    "    # To get maximum memory duration, we need to specify the following average\n",
    "    # memory value\n",
    "    avg_mem = round(args['max_memory'] / 3.0 + 0.01, 2)\n",
    "\n",
    "    objset = task.generate_objset(n_distractor=0,average_memory_span=avg_mem, *args, **kwargs)\n",
    "            # objset: sg.ObjectSet, epoch_now: int, should_be=None, temporal_switch=False\n",
    "\n",
    "    # Getting targets can remove some objects from objset.\n",
    "    # Create example fields after this call.\n",
    "    frame_info = ig.FrameInfo(task, objset)\n",
    "    compo_info = ig.TaskInfoCompo(task, frame_info)\n",
    "    return compo_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_temporal_example(max_memory, max_distractors, task_family,\n",
    "                              whens=None, first_shareable=None, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    generate 1 task objset and composition info object\n",
    "\n",
    "    :param max_memory:\n",
    "    :param max_distractors:\n",
    "    :param task_family:\n",
    "    :param whens:\n",
    "    :param first_shareable:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    task = task_bank.random_task(task_family, whens, first_shareable)\n",
    "    assert isinstance(task, tg.TemporalTask)\n",
    "\n",
    "    # To get maximum memory duration, we need to specify the following average\n",
    "    # memory value\n",
    "    avg_mem = round(max_memory / 3.0 + 0.01, 2)\n",
    "    if max_distractors == 0:\n",
    "        objset = task.generate_objset(average_memory_span=avg_mem, *args, **kwargs)\n",
    "    else:\n",
    "        objset = task.generate_objset(n_distractor=random.randint(1, max_distractors),\n",
    "                                      average_memory_span=avg_mem, *args, **kwargs)\n",
    "    # Getting targets can remove some objects from objset.\n",
    "    # Create example fields after this call.\n",
    "    frame_info = ig.FrameInfo(task, objset)\n",
    "    compo_info = ig.TaskInfoCompo(task, frame_info)\n",
    "    return compo_info\n",
    "\n",
    "\n",
    "def generate_compo_temporal_example(max_memory, max_distractors, families, n_tasks=1,\n",
    "                                    *args, **kwargs):\n",
    "    '''\n",
    "\n",
    "    :param first_shareable:\n",
    "    :param whens:\n",
    "    :param families:\n",
    "    :param max_memory:\n",
    "    :param max_distractors:\n",
    "    :param n_tasks:\n",
    "    :return: combined TaskInfo Compo\n",
    "    '''\n",
    "\n",
    "    whens = kwargs.pop('whens', [None for _ in range(n_tasks)])\n",
    "\n",
    "    if not isinstance(whens[0], list):\n",
    "        whens = [whens for _ in range(n_tasks)]\n",
    "    if n_tasks == 1:\n",
    "        return generate_temporal_example(max_memory, max_distractors, families, whens=whens[0], *args, **kwargs)\n",
    "\n",
    "    compo_tasks = [generate_temporal_example(max_memory, max_distractors, families, whens=whens[i], *args, **kwargs)\n",
    "                   for i in range(n_tasks)]\n",
    "    # temporal combination\n",
    "    cur_task = compo_tasks[0]\n",
    "    for task in compo_tasks[1:]:\n",
    "        cur_task.merge(task)\n",
    "    return cur_task\n",
    "\n",
    "\n",
    "# TODO: split training and validation after task generation\n",
    "\n",
    "def generate_dataset(examples_per_family, output_dir='./data',\n",
    "                     random_families=True, families=None,\n",
    "                     composition=1, img_size=224,\n",
    "                     train=0.7, validation=0.3, fixation_cue=True,\n",
    "                     *args, **kwargs):\n",
    "    if not random_families:\n",
    "        assert families is not None\n",
    "        assert composition == len(families)\n",
    "    assert train + validation == 1.0\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # TODO: add task_family order instance folders\n",
    "    #  e.g. families = [CompareLoc, CompareCat] could have 4 different task orders\n",
    "    families_count = defaultdict(lambda: 0)\n",
    "    if families is None or families == 'all':\n",
    "        families = list(task_bank.task_family_dict.keys())\n",
    "    print(families)\n",
    "    n_families = len(families)\n",
    "    total_examples = n_families * examples_per_family\n",
    "    train_examples = total_examples * train\n",
    "    validation_examples = total_examples * validation\n",
    "\n",
    "    # creating task folder names\n",
    "    fam_str = '_'.join(families)\n",
    "    if train != 0.7 and validation != 0.3:\n",
    "        base_fname = os.path.join(output_dir,\n",
    "                                  f'tasks_{fam_str}_{train}_{validation}')\n",
    "    else:\n",
    "        base_fname = os.path.join(output_dir,\n",
    "                                  f'tasks_{fam_str}')\n",
    "\n",
    "    train_fname = os.path.join(base_fname, 'train')\n",
    "    validation_fname = os.path.join(base_fname, 'validation')\n",
    "\n",
    "    if not os.path.exists(train_fname):\n",
    "        os.makedirs(train_fname)\n",
    "    if not os.path.exists(validation_fname):\n",
    "        os.makedirs(validation_fname)\n",
    "\n",
    "    # TODO: temporal_switch generation pipeline. User specify compo vs switch or randomly.\n",
    "    #  If randomly, how to split compo and switch?\n",
    "    if random_families:\n",
    "        p = np.random.permutation(total_examples)\n",
    "        i = 0\n",
    "        while i < len(p):\n",
    "            if i % 10000 == 0 and i > 0:\n",
    "                print(\"Generated \", i, \" examples\")\n",
    "\n",
    "            task_family = list()\n",
    "            for j in range(composition):\n",
    "                task_family.append(families[p[i] % n_families])\n",
    "                families_count[families[p[i] % n_families]] += 1\n",
    "\n",
    "            info = generate_compo_temporal_example(families=task_family, n_tasks=composition, *args, **kwargs)\n",
    "            # Write the example randomly to training or validation folder\n",
    "            split = bool(random.getrandbits(1))\n",
    "            if (split or validation_examples <= 0) and train_examples > 0:\n",
    "                train_examples -= 1\n",
    "                fname = os.path.join(train_fname, f'{i}')\n",
    "            else:\n",
    "                validation_examples -= 1\n",
    "                fname = os.path.join(validation_fname, f'{i}')\n",
    "\n",
    "            write_task_instance(fname, info, img_size, fixation_cue)\n",
    "            i += 1\n",
    "    else:\n",
    "        i = 0\n",
    "        while i < total_examples:\n",
    "            if i % 10000 == 0 and i > 0:\n",
    "                print(\"Generated \", i, \" examples\")\n",
    "            task_family = np.random.permutation(families)\n",
    "\n",
    "            compo_tasks = [generate_temporal_example(task_family=[family], *args, **kwargs)\n",
    "                           for family in task_family]\n",
    "            # temporal combination\n",
    "            info = compo_tasks[0]\n",
    "            for task in compo_tasks[1:]:\n",
    "                info.merge(task)\n",
    "            # TODO: find boolean output task and apply temporal switch\n",
    "            #  draw diagram for branching structure of temporal composition/switch\n",
    "            #  put in info_generator?\n",
    "            info.temporal_switch()\n",
    "\n",
    "            # Write the example randomly to training or validation folder\n",
    "            split = bool(random.getrandbits(1))\n",
    "            if (split or validation_examples <= 0) and train_examples > 0:\n",
    "                train_examples -= 1\n",
    "                fname = os.path.join(train_fname, f'{i}')\n",
    "            else:\n",
    "                validation_examples -= 1\n",
    "                fname = os.path.join(validation_fname, f'{i}')\n",
    "\n",
    "            write_task_instance(fname, info, img_size, fixation_cue)\n",
    "            i += 1\n",
    "    return families_count\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = get_args()\n",
    "    print(args)\n",
    "\n",
    "    const.DATA = const.Data(args.stim_dir)\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    if args.nback > 0:\n",
    "        assert all('Compare' in family for family in args.families)\n",
    "        whens = [f'last{args.nback}', 'last0']\n",
    "        composition = args.nback_length - args.nback + 1\n",
    "        generate_dataset(examples_per_family=args.trials_per_family, output_dir=args.output_dir,\n",
    "                         composition=composition, img_size=args.img_size,\n",
    "                         random_families=args.random_families, families=args.families,\n",
    "                         train=args.training, validation=args.validation, fixation_cue=args.fixation_cue,\n",
    "                         max_memory=args.max_memory, max_distractors=args.max_distractors,\n",
    "                         whens=whens, first_shareable=1, temporal_switch=args.temporal_switch)\n",
    "    elif args.seq_length > 0:\n",
    "        first_shareable = 1\n",
    "\n",
    "        if args.seq_reverse:\n",
    "            # minimum 2 frames per DMS task\n",
    "            if args.seq_length * 2 - 1 > const.MAX_MEMORY:\n",
    "                raise ValueError('Not enough max memory')\n",
    "            whens = [[f'last{const.MAX_MEMORY - (i * 2)}', 'last0'] for i in range(args.seq_length)]\n",
    "        else:\n",
    "            last_when = sg.random_when()\n",
    "            while int(re.search(r'\\d+', last_when).group()) - 1 < args.seq_length:\n",
    "                last_when = sg.random_when()\n",
    "            whens = [[last_when, 'last0'] for _ in range(args.seq_length)]\n",
    "        generate_dataset(examples_per_family=args.trials_per_family, output_dir=args.output_dir,\n",
    "                         composition=args.seq_length, img_size=args.img_size,\n",
    "                         random_families=args.random_families, families=args.families,\n",
    "                         train=args.training, validation=args.validation, fixation_cue=args.fixation_cue,\n",
    "                         max_memory=args.max_memory, max_distractors=args.max_distractors,\n",
    "                         whens=whens, first_shareable=first_shareable, temporal_switch=args.temporal_switch)\n",
    "    else:\n",
    "        whens = [\"last0\", \"last1\"] # xlei: previously Mark set this as None\n",
    "        if args.fix_delay:\n",
    "            # TODO: move this into task.init\n",
    "            whens = [f'last{const.DATA.MAX_MEMORY}', 'last0']\n",
    "        generate_dataset(examples_per_family=args.trials_per_family, output_dir=args.output_dir,\n",
    "                         composition=args.composition, img_size=args.img_size,\n",
    "                         random_families=args.random_families, families=args.families,\n",
    "                         train=args.training, validation=args.validation, fixation_cue=args.fixation_cue,\n",
    "                         max_memory=args.max_memory, max_distractors=args.max_distractors,\n",
    "                         whens=whens, first_shareable=None, temporal_switch=args.temporal_switch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bashlab_cogenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
