{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torchvision\n",
    "from tqdm.notebook import tqdm\n",
    "import copy\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = 'datasets/trials'\n",
    "BATCH_SIZE = 1\n",
    "MAX_FRAMES = 3\n",
    "VIT_OUT_DIM = 1000\n",
    "LM_OUT_DIM = 768\n",
    "ACT_TOKEN = '[ACT]'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3]).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "infos = []\n",
    "\n",
    "for trial_fp in os.listdir(DIR):\n",
    "    trial_fp = os.path.join(DIR, trial_fp)\n",
    "    imgs = []\n",
    "    for fp in os.listdir(trial_fp):\n",
    "        fp = os.path.join(trial_fp, fp)\n",
    "        if fp[-4:] == '.png':\n",
    "            imgs.append(np.rollaxis(np.array(Image.open(fp), dtype=np.float32),2,0))\n",
    "        else:\n",
    "            infos.append(json.load(open(fp)))\n",
    "    frames.append(np.array(imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = [x['instruction'] for x in infos]\n",
    "target_actions = [x['answers'] for x in infos]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstructionsDataset(Dataset):\n",
    "  \"\"\"\n",
    "    Pytorch Dataset class to load the Instructions Data\n",
    "\n",
    "    Data members:\n",
    "      instructions: list of instructions\n",
    "      n_ins: number of instructions in the dataset\n",
    "\n",
    "    Member functions:\n",
    "      __init__: ctor\n",
    "      __len__: returns n_ins\n",
    "      __getitem__: returns an instruction\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, x):\n",
    "\n",
    "    self.instructions = x\n",
    "\n",
    "    self.n_ins = len(self.instructions)\n",
    "\n",
    "    return\n",
    "\n",
    "  def __len__(self):\n",
    "    \"\"\"\n",
    "      Returns number of instructions in the Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    return self.n_ins\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    \"\"\"\n",
    "      Given an index return a instruction at that index\n",
    "    \"\"\"\n",
    "\n",
    "    return self.instructions[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstructionsCollator(object):\n",
    "  \"\"\"\n",
    "    Data Collator used for GPT2 in a classificaiton tasks\n",
    "\n",
    "    Args:\n",
    "      use_tokenizer :\n",
    "        Transformer type tokenizer used to process raw text into numbers.\n",
    "\n",
    "    Data members:\n",
    "      use_tokenizer: Tokenizer to be used inside the class.\n",
    "\n",
    "    Member functions:\n",
    "      __init__: ctor\n",
    "      __call__: tokenize input\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "  def __init__(self, use_tokenizer):\n",
    "\n",
    "    self.use_tokenizer = use_tokenizer\n",
    "\n",
    "    return\n",
    "\n",
    "  def __call__(self, instructions):\n",
    "    \"\"\"\n",
    "        Tokenizes input\n",
    "    \"\"\"\n",
    "\n",
    "    # Call tokenizer\n",
    "    inputs = self.use_tokenizer(instructions, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_encoder = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Create data collator to encode text and labels into numbers.\n",
    "InstructionsCollator = InstructionsCollator(use_tokenizer=tokenizer)\n",
    "\n",
    "# Create pytorch dataset for instructions\n",
    "ins_train_dataset = InstructionsDataset(instructions)\n",
    "\n",
    "# Move pytorch dataset into dataloader \n",
    "ins_train_dataloader = DataLoader(ins_train_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=InstructionsCollator)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frames Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FramesDataset(Dataset):\n",
    "  \"\"\"\n",
    "    Pytorch Dataset class to load the Frame Data\n",
    "\n",
    "    Data members:\n",
    "      frames``ist of frames\n",
    "      n_imgs: number of iamges in the dataset\n",
    "\n",
    "    Member functions:\n",
    "      __init__: ctor\n",
    "      __len__: returns n_imgs\n",
    "      __getitem__: returns an frame\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, x):\n",
    "\n",
    "    self.frames = x\n",
    "\n",
    "    self.n_imgs = len(self.frames)\n",
    "\n",
    "    return\n",
    "\n",
    "  def __len__(self):\n",
    "    \"\"\"\n",
    "      Returns number of frames in the Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    return self.n_imgs\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    \"\"\"\n",
    "      Given an index return a frame\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.tensor(self.frames[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_encoder = torchvision.models.vit_b_16(weights=torchvision.models.ViT_B_16_Weights.DEFAULT)\n",
    "\n",
    "# Create pytorch dataset for instructions\n",
    "frames_train_dataset = FramesDataset(frames)\n",
    "\n",
    "# Move pytorch dataset into dataloader \n",
    "frames_train_dataloader = DataLoader(frames_train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_embedder(instruction, encoder):\n",
    "    #Mean Pooling - Take attention mask into account for correct averaging\n",
    "    def mean_pooling(model_output, attention_mask):\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        lm_output = encoder(**instruction)\n",
    "        # print(lm_output[0].size())\n",
    "        # print(lm_output.pooler_output.shape)\n",
    "\n",
    "    # Perform pooling\n",
    "    sentence_embeddings = mean_pooling(lm_output, instruction['attention_mask'])\n",
    "    \n",
    "    # Normalize embeddings\n",
    "    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "        \n",
    "    return sentence_embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_embedder(frames, encoder):\n",
    "    with torch.no_grad():\n",
    "        vit_out = encoder(torch.tensor(frames))\n",
    "\n",
    "    npads = MAX_FRAMES-len(vit_out)\n",
    "    pad = torch.ones((npads, vit_out.shape[1]))\n",
    "    vit_out = torch.cat((vit_out, pad))\n",
    "\n",
    "    return vit_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_2184\\3025187430.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  vit_out = encoder(torch.tensor(frames))\n"
     ]
    }
   ],
   "source": [
    "lm_embeddings = []\n",
    "img_embeddings = []\n",
    "\n",
    "for i,f in zip(ins_train_dataloader,frames_train_dataloader):\n",
    "   f = f[0]\n",
    "   lm_embeddings.append(lm_embedder(i, lm_encoder))\n",
    "   img_embeddings.append(img_embedder(f, vit_encoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1000])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lm_embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import projections\n",
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class CausalMatchTransformer(nn.Module):\n",
    "\n",
    "    # Initialize Model with Params\n",
    "    def __init__(self, nframes=MAX_FRAMES, blocks=3, nhead=5, emb_dim=VIT_OUT_DIM, device=device):\n",
    "        super().__init__()\n",
    "\n",
    "        # Device\n",
    "        self.device = device\n",
    "\n",
    "        # Number of frames\n",
    "        self.nframes = nframes\n",
    "\n",
    "        # Frame Position Embedder Layer\n",
    "        self.pos_emb = nn.Embedding(nframes,emb_dim)\n",
    "        self.pos_emb.weight = nn.init.xavier_uniform_(self.pos_emb.weight)\n",
    "\n",
    "        # Instruction Dim Projection Layer\n",
    "        self.lm_linear_layer = nn.Linear(LM_OUT_DIM, emb_dim).to(device)\n",
    "\n",
    "        # Decoder Layers\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=emb_dim, nhead=nhead, batch_first=True).to(device)\n",
    "        self.decoder_layers = _get_clones(self.decoder_layer, blocks)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.TransformerDecoder(self.decoder_layers, num_layers=blocks).to(device)\n",
    "\n",
    "    # Function for forward pass\n",
    "    def forward(self, instruction, frames, mask):\n",
    "\n",
    "        output = self.lm_linear_layer(instruction)\n",
    "        print(output.shape)\n",
    "\n",
    "        for i in range(len(frames)):\n",
    "            frames[i] += self.pos_emb(torch.tensor([i]))[0]\n",
    "\n",
    "        print(frames.shape)\n",
    "\n",
    "        for layer in self.decoder_layers:\n",
    "            output = layer(output, frames, memory_mask=mask, memory_is_causal=True) \n",
    "            # (tgt, memory, tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None, tgt_is_causal=False, memory_is_causal=False)\n",
    "\n",
    "        return output\n",
    "\n",
    "    # Generates a padding masks for each sequence in a batch\n",
    "    def generate_pad_mask(self, batch):\n",
    "\n",
    "        pad_tensor = torch.ones((batch.shape[2])).to(device)\n",
    "\n",
    "        mask = np.zeros((batch.shape[0],batch.shape[1]))\n",
    "\n",
    "        for s in range(0, batch.shape[0]):\n",
    "            for v in range(0, batch[s].shape[0]):\n",
    "                new_s = torch.all(batch[s][v] == pad_tensor)\n",
    "                mask[s][v] = new_s\n",
    "\n",
    "        return torch.tensor(mask).bool().to(self.device)\n",
    "    \n",
    "# Creates a list of torch duplicate torch modules\n",
    "def _get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "def generate_causal_mask(sz: int) -> Tensor:\n",
    "    \n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
    "\n",
    "def generate_pad_mask(batch):\n",
    "\n",
    "    pad_tensor = torch.ones((batch.shape[2])).to(device)\n",
    "    \n",
    "    mask = np.zeros((batch.shape[0],batch.shape[1]))\n",
    "\n",
    "    for s in range(0, batch.shape[0]):\n",
    "        for v in range(0, batch[s].shape[0]):\n",
    "            new_s = torch.all(batch[s][v] == pad_tensor)\n",
    "            mask[s][v] = new_s\n",
    "\n",
    "    return torch.tensor(mask).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m generate_pad_mask(img_embeddings[\u001b[39m0\u001b[39;49m])\n",
      "Cell \u001b[1;32mIn[17], line 79\u001b[0m, in \u001b[0;36mgenerate_pad_mask\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_pad_mask\u001b[39m(batch):\n\u001b[1;32m---> 79\u001b[0m     pad_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones((batch\u001b[39m.\u001b[39;49mshape[\u001b[39m2\u001b[39;49m]))\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     81\u001b[0m     mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((batch\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],batch\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]))\n\u001b[0;32m     83\u001b[0m     \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, batch\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "generate_pad_mask(img_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = generate_causal_mask(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x24490286d70>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = CausalMatchTransformer(nframes=MAX_FRAMES,\n",
    "                               blocks=3,\n",
    "                               nhead=5,\n",
    "                               emb_dim=VIT_OUT_DIM,\n",
    "                               device=device).float().to(device)\n",
    "\n",
    "# Configurations\n",
    "epochs = 50\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = torch.optim.Adam(\n",
    "    (p for p in model.parameters() if p.requires_grad), lr=lr\n",
    ")\n",
    "\n",
    "# mask = generate_causal_mask(nframes).to(device)\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n",
      "torch.Size([3, 1000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8306e-01, -5.1776e-01,  8.9032e-01,  1.9375e+00, -2.3336e+00,\n",
       "         -1.3268e-01, -3.1556e-01, -7.2657e-01, -3.8252e-01,  1.9251e+00,\n",
       "          8.9533e-02, -1.2222e+00,  7.6961e-01, -1.0597e-01,  2.8875e-01,\n",
       "          1.4073e+00,  1.1090e+00, -1.0718e+00, -3.7788e-01,  3.3507e-02,\n",
       "         -3.5546e-01,  1.2348e+00, -1.6011e-01, -9.6531e-03,  6.3008e-01,\n",
       "         -1.1621e+00, -3.2967e-01, -1.5035e+00, -2.1828e-01,  9.6674e-01,\n",
       "          1.0783e+00, -4.7478e-01, -5.1392e-01, -2.2237e+00, -9.4348e-01,\n",
       "          1.5781e-01, -7.6803e-03,  1.4587e+00,  4.3916e-01,  9.6735e-01,\n",
       "          5.3521e-01,  8.4843e-01, -7.2493e-01,  1.3833e+00,  4.5249e-02,\n",
       "          1.5873e+00,  4.9201e-01, -8.4563e-01,  1.2811e+00,  5.4231e-01,\n",
       "         -7.3969e-01,  2.5398e-01, -3.0924e-01, -3.4320e-01, -7.9116e-02,\n",
       "          1.0126e+00, -1.8734e+00, -6.6332e-01, -6.0073e-02,  9.2261e-01,\n",
       "         -1.2868e-01,  6.6847e-01, -1.4634e+00, -2.5370e-01, -1.7727e+00,\n",
       "          7.9013e-01,  1.0150e+00, -1.1364e+00, -4.1527e-01, -6.3150e-01,\n",
       "          1.1959e+00,  1.2676e+00, -1.1520e+00,  3.8823e-01,  3.9039e-01,\n",
       "          8.5974e-02, -1.8323e-01, -4.2540e-01,  3.2808e-01, -6.4780e-01,\n",
       "          5.4421e-01, -1.0003e+00,  5.6401e-01,  1.3607e+00, -1.3921e+00,\n",
       "         -3.6850e-01,  6.7760e-01, -2.4593e+00, -1.2535e+00, -3.3314e-01,\n",
       "          1.6151e+00, -3.9725e-02,  1.1454e+00,  2.5446e-01,  5.1133e-01,\n",
       "          9.1250e-02, -7.7277e-01, -6.0688e-01,  4.8476e-01, -4.4016e-01,\n",
       "          2.2223e-01,  5.4766e-02, -2.8987e-01, -7.2263e-01,  1.0913e+00,\n",
       "          8.7279e-01, -5.2845e-01, -1.0756e+00, -1.7981e-01, -7.2276e-01,\n",
       "         -1.4387e-01, -9.2594e-01, -4.6281e-01,  1.0190e+00, -1.3118e-01,\n",
       "         -2.9879e-02, -1.3863e+00,  1.8786e+00, -1.4976e+00,  5.6220e-01,\n",
       "          2.7095e-01, -1.0248e+00, -6.8861e-01, -2.7357e-01, -3.1798e+00,\n",
       "          7.8698e-01,  7.4401e-01, -2.1804e-02, -7.6571e-01, -2.8023e-02,\n",
       "          4.2557e-01,  7.4832e-01, -1.9191e-02, -1.8877e+00, -8.5620e-01,\n",
       "         -1.0083e+00,  7.9901e-01,  6.8786e-01,  8.2632e-01,  1.6758e-01,\n",
       "          8.1919e-01,  8.1450e-01, -1.5592e+00,  2.3401e+00, -3.7813e-01,\n",
       "          1.0182e+00, -6.0018e-01,  2.7560e-01,  9.9578e-01,  6.9454e-01,\n",
       "          8.4524e-01, -2.1469e-01,  1.4545e+00,  1.2000e+00, -4.8243e-01,\n",
       "         -1.9020e+00,  1.5665e+00, -1.7813e-01, -4.7765e-01, -1.0161e+00,\n",
       "          5.9972e-01,  1.5788e+00, -5.4201e-01, -5.4978e-01,  3.5455e-02,\n",
       "         -7.4977e-01, -7.5386e-02,  1.8832e+00, -4.7192e-01, -1.0522e-01,\n",
       "          1.1888e+00,  9.5396e-01,  4.6845e-02, -1.4146e-01, -8.6173e-01,\n",
       "          3.3013e-01, -8.1980e-01, -8.1151e-01, -4.1822e-01, -1.5909e+00,\n",
       "          8.0150e-01,  6.9515e-01, -1.2599e-01, -5.7644e-01, -2.5938e-01,\n",
       "          1.7391e-01,  1.0355e+00,  8.1519e-01,  5.8416e-02,  2.8706e+00,\n",
       "         -6.1820e-01, -1.2105e+00, -3.9695e-01,  1.3786e+00,  1.4004e+00,\n",
       "         -1.0691e+00,  1.7906e+00,  7.8614e-02, -1.9586e-01, -1.2622e-01,\n",
       "         -1.0366e+00, -1.2485e-01, -8.6873e-01, -8.0273e-01,  3.7884e-01,\n",
       "          3.0668e-01, -9.9210e-01, -1.3066e+00,  7.1508e-01, -1.2090e+00,\n",
       "         -4.9348e-01,  1.2597e+00, -7.5036e-01,  7.9810e-01,  7.3202e-01,\n",
       "         -5.3090e-01,  1.4716e+00,  1.2451e+00, -1.5920e-01,  1.8143e-01,\n",
       "         -1.8392e+00, -9.0362e-01, -1.0103e+00,  1.0718e-01,  6.2809e-01,\n",
       "         -3.4799e-01,  4.2910e-01, -7.4017e-01, -1.0261e+00, -5.9998e-01,\n",
       "         -6.4922e-02, -2.1942e+00,  3.6533e-01, -1.1029e+00,  3.3063e-02,\n",
       "         -9.6349e-01,  1.3026e+00,  1.2003e+00,  1.0780e+00, -1.4949e+00,\n",
       "          4.9738e-01,  9.9288e-02, -1.2050e+00, -1.8573e-01, -1.1665e+00,\n",
       "         -2.5292e-01, -1.5218e+00,  1.6114e+00, -3.4353e-01, -1.6417e-01,\n",
       "          1.2448e+00, -6.9014e-01,  9.5473e-01, -1.5474e-01,  5.2243e-02,\n",
       "          2.8509e-01,  9.9860e-01, -1.3021e+00, -5.9606e-01,  4.3681e-01,\n",
       "         -7.8159e-01,  1.7501e-01, -9.7775e-01,  1.7263e+00,  3.2862e-01,\n",
       "          1.7696e-01, -1.2683e+00,  2.4412e+00, -1.6835e+00, -1.5176e+00,\n",
       "          6.0649e-01,  8.6066e-01, -9.9238e-01,  8.8490e-01, -1.7816e+00,\n",
       "         -8.4068e-01, -5.0001e-01, -6.2708e-01,  1.7393e+00,  1.4015e+00,\n",
       "         -2.0573e+00,  7.8193e-01, -2.5864e-01,  3.9912e-01,  1.3314e+00,\n",
       "          3.3218e-01,  1.0195e+00, -1.2090e+00,  7.4633e-01,  1.3014e-01,\n",
       "          7.1214e-02, -1.8169e-01, -1.6826e-01, -1.5831e+00, -1.1012e+00,\n",
       "         -7.5717e-01, -2.7118e-01,  6.3213e-01,  3.9540e-01, -2.4942e+00,\n",
       "         -6.2493e-01, -8.1463e-01, -1.2021e+00,  1.0697e+00, -1.8956e+00,\n",
       "          1.3201e+00, -1.0665e+00, -1.7233e-01, -2.6296e-01,  1.4887e+00,\n",
       "          7.4227e-01,  1.0226e-01,  9.6887e-01, -4.3897e-02,  7.9148e-01,\n",
       "         -1.3424e+00,  1.1300e+00,  1.8804e+00,  1.2252e+00,  1.0681e+00,\n",
       "          4.3971e-01,  2.1802e-01,  1.1752e+00,  9.7164e-01,  3.5529e-01,\n",
       "         -1.9591e-01, -7.4100e-01, -3.4559e-01,  2.6674e+00, -2.6212e-02,\n",
       "         -7.9704e-01, -6.2991e-01,  1.7889e+00,  2.3309e-01, -3.5929e-01,\n",
       "          2.0821e+00, -5.1432e-01, -4.3370e-01, -9.0799e-01,  8.7512e-02,\n",
       "          3.3463e-01,  1.2433e-01, -1.7562e+00,  4.7308e-02,  5.9938e-01,\n",
       "          1.3414e+00,  1.6090e+00, -9.2102e-01,  7.8777e-01,  7.2012e-01,\n",
       "          1.3687e-01,  7.0686e-01,  9.5460e-01,  1.1926e+00,  4.4817e-01,\n",
       "          4.0539e-01, -9.9168e-01,  7.3537e-01,  2.6040e+00,  6.5153e-01,\n",
       "          4.4090e-01,  7.1717e-01,  2.9204e-01,  5.4629e-01,  1.2883e+00,\n",
       "         -3.4823e-01, -8.4656e-02, -4.4917e-01,  3.8917e-01, -6.9916e-01,\n",
       "          1.0152e-01, -2.0307e-01,  9.5303e-01,  6.4149e-01,  1.8054e-01,\n",
       "          2.1373e-01,  9.8063e-01, -1.2825e+00,  5.0164e-01, -1.0623e+00,\n",
       "          1.5207e+00, -1.5947e+00, -6.8650e-01,  1.3239e+00,  1.9154e+00,\n",
       "         -3.6995e-01,  3.8107e-02, -1.1571e+00,  5.8665e-01, -2.2056e+00,\n",
       "          5.8017e-01,  2.2721e+00,  8.2970e-02, -1.3475e+00,  1.0785e+00,\n",
       "          1.0638e+00, -1.8133e-01,  1.3377e+00,  2.3808e-01,  1.4628e+00,\n",
       "          7.4809e-02,  3.2004e+00,  3.0031e-01,  1.7229e+00, -8.7060e-01,\n",
       "          6.6980e-02,  2.3637e-01, -2.6391e-01,  4.4322e-01,  9.3577e-01,\n",
       "         -9.9525e-02, -1.0298e-01, -1.3927e+00,  1.6408e+00, -2.2425e-01,\n",
       "          1.4673e+00,  6.3841e-01,  1.5706e+00, -8.5798e-01, -3.8475e-01,\n",
       "          1.4568e-01, -3.7839e-01, -1.9007e-01, -2.0649e-01, -6.7189e-01,\n",
       "          6.0069e-01, -6.3729e-01,  1.0570e-01, -1.9670e-01, -7.4052e-01,\n",
       "          3.8126e-01,  7.0606e-01,  4.7041e-01, -1.0436e+00,  1.1515e+00,\n",
       "         -1.1028e+00, -1.5904e+00, -7.9740e-01,  6.5843e-01,  8.1406e-01,\n",
       "         -7.4895e-01, -7.0240e-01, -2.3137e+00, -1.6564e-01, -3.2716e-01,\n",
       "         -2.2564e-01,  2.7871e-02,  5.7253e-02,  2.3499e+00, -3.7090e-01,\n",
       "          3.3587e-01,  7.6287e-02,  5.3355e-01, -1.1508e+00,  5.6355e-01,\n",
       "         -1.5282e-01, -4.1694e-01,  1.5816e+00, -3.9985e-01,  2.5005e+00,\n",
       "          1.1645e+00,  7.2236e-02,  8.1929e-01,  8.2950e-01,  5.1049e-01,\n",
       "         -1.9041e+00,  4.2041e-01, -8.3321e-01, -1.3762e+00, -1.6941e+00,\n",
       "         -1.8873e-01, -1.7340e-01, -6.1403e-01,  1.2051e+00,  1.2981e+00,\n",
       "          2.1505e-04,  1.9876e-01,  8.6237e-01, -2.3214e-01, -4.2708e-01,\n",
       "          9.5989e-02, -3.3604e-01, -4.2331e-01, -5.0743e-02,  5.9822e-01,\n",
       "         -7.4531e-02,  1.6816e+00,  1.5236e+00,  5.8382e-01,  3.8626e-02,\n",
       "         -1.1305e-01, -5.8300e-01, -1.2106e+00, -4.5183e-01, -1.1154e-01,\n",
       "         -1.5224e+00,  6.9658e-01,  1.9952e-01, -1.3079e-01, -1.3821e-01,\n",
       "         -1.2836e+00,  1.0334e+00, -2.3431e-01,  1.2751e+00,  8.2219e-02,\n",
       "          7.9440e-02, -2.1707e+00, -4.8993e-01,  2.0288e-02, -6.9361e-01,\n",
       "         -2.5098e-01, -1.0282e+00, -6.9732e-01,  4.6376e-01,  5.4859e-02,\n",
       "         -9.6486e-01, -1.4296e+00,  1.0017e+00,  7.7174e-01, -3.2021e-01,\n",
       "          1.2281e+00,  2.6877e+00,  1.6715e+00, -1.6651e+00, -1.5769e+00,\n",
       "          2.8585e+00,  2.2801e-01,  1.0063e+00, -1.6474e+00,  7.4184e-01,\n",
       "          1.1028e+00, -1.9180e-01,  4.6790e-01, -2.3880e+00,  1.0450e+00,\n",
       "         -4.5737e-01,  1.0713e+00,  3.0755e-01,  6.1356e-01,  3.2075e-01,\n",
       "         -1.0365e+00, -8.4106e-02,  1.6774e+00, -1.5242e+00, -1.1776e+00,\n",
       "         -1.6930e-01, -1.4394e+00,  2.0250e+00, -7.3125e-01, -3.6069e-01,\n",
       "          7.7865e-01, -2.3587e-01, -3.9132e-01, -2.6103e-01, -1.3139e+00,\n",
       "          1.5108e+00, -1.2185e+00, -2.1397e-01,  4.1636e-01, -1.6178e+00,\n",
       "         -8.9058e-01, -1.3895e-01,  1.0226e+00,  2.5055e+00, -1.9876e+00,\n",
       "         -1.0453e+00,  1.6117e+00, -5.2528e-01,  4.9478e-01, -3.8754e-02,\n",
       "          6.3854e-01, -1.9068e-01,  8.4251e-01,  1.5531e+00,  3.9830e-01,\n",
       "          2.7922e-01, -1.2477e+00,  7.4666e-01, -4.7354e-01, -3.0271e-01,\n",
       "          3.4909e-01,  1.3897e+00, -3.7893e-01,  1.8469e+00, -4.3809e-01,\n",
       "         -1.6314e+00,  1.4321e+00,  4.6603e-01, -6.6343e-01, -1.1539e+00,\n",
       "          4.2793e-01, -1.4062e-01, -3.9047e-01,  2.3934e+00, -9.5462e-01,\n",
       "          6.0039e-01, -5.9476e-01, -7.2806e-01,  3.8041e-01, -1.5266e+00,\n",
       "         -2.5548e-01,  7.0862e-01, -6.6160e-01, -4.1847e-01, -6.8075e-02,\n",
       "         -1.6058e+00, -1.7420e-01,  5.2531e-01,  1.1038e+00,  8.5345e-01,\n",
       "         -6.8143e-01,  3.8536e-01,  9.2378e-01, -3.7398e-01, -1.8771e+00,\n",
       "          1.4674e+00,  2.2913e+00,  5.0665e-01,  3.1926e-01,  1.6358e-01,\n",
       "         -1.0773e+00,  6.9334e-01, -1.4999e-01,  1.1998e+00, -1.5840e+00,\n",
       "         -1.8064e+00,  2.4311e-01,  6.0545e-01, -1.9048e-01, -6.2427e-01,\n",
       "         -3.0509e-01, -9.0591e-01, -1.1498e+00,  5.8877e-01,  2.5167e-01,\n",
       "          1.3587e+00, -5.0625e-01, -6.2810e-01, -8.7697e-01, -6.6479e-01,\n",
       "          6.0249e-01,  6.4247e-01,  1.7751e-01, -2.2644e-01,  8.0764e-01,\n",
       "         -3.0848e-01, -1.4072e-02, -9.6506e-01,  2.3432e-01, -1.4930e-02,\n",
       "          6.9546e-01, -1.0595e+00,  1.0244e+00,  8.3206e-02, -1.9645e+00,\n",
       "          1.8862e-01, -8.1017e-01, -9.2238e-01,  3.2081e-01,  7.0883e-01,\n",
       "          4.2414e-02,  1.6410e-01,  3.6101e-01,  7.2762e-02,  4.8128e-01,\n",
       "          1.9908e+00,  6.8988e-01,  7.3822e-01,  1.9422e-01,  8.5217e-02,\n",
       "          2.3072e-01,  5.4514e-01, -9.7163e-01, -9.2092e-03,  1.4659e+00,\n",
       "          9.6057e-01,  2.1189e+00,  4.1522e-01, -2.4432e-01, -5.1695e-01,\n",
       "          1.4120e+00, -8.9712e-01,  7.8814e-01, -1.0691e+00,  1.0336e+00,\n",
       "         -1.1131e+00, -1.8160e+00,  1.0478e-01, -8.0823e-01,  7.4491e-02,\n",
       "         -1.6001e+00,  1.7589e+00,  2.3922e+00, -1.7650e+00, -1.8101e+00,\n",
       "         -1.2149e+00,  1.6848e-01, -1.1584e+00,  3.0750e-01,  4.5246e-01,\n",
       "         -8.7492e-01,  9.1526e-01, -7.8637e-02, -4.1566e-01,  9.1418e-01,\n",
       "          8.3147e-01, -1.4526e+00, -4.9986e-01,  5.0227e-01, -1.8956e-01,\n",
       "         -1.7635e+00,  3.4022e-01, -7.1789e-01,  7.2673e-01,  3.9363e-01,\n",
       "          1.3540e-01,  5.2761e-01,  9.3261e-01,  1.1973e+00, -2.0784e+00,\n",
       "         -8.2884e-01, -7.1786e-01, -1.6147e+00, -4.4708e-01,  6.0979e-01,\n",
       "         -4.9417e-01,  1.7865e-01, -4.7297e-01, -7.6227e-01,  4.9491e-01,\n",
       "         -1.6730e-01,  1.2530e-01,  2.0047e+00,  3.8911e-01, -2.9905e-01,\n",
       "          6.8579e-01, -1.7007e+00,  2.4990e-01, -7.6542e-01, -1.3713e+00,\n",
       "          9.2026e-01,  1.1384e+00,  3.3923e-01,  4.2149e-01,  5.7498e-01,\n",
       "         -1.6207e-01, -1.0605e+00, -9.7772e-01,  2.0069e+00, -6.7041e-01,\n",
       "         -3.1476e-01, -1.1502e+00, -1.1212e+00, -1.0360e+00, -4.8324e-01,\n",
       "          6.0116e-02,  1.2532e+00, -7.8487e-01,  7.3615e-01, -1.0376e+00,\n",
       "          9.6059e-02,  7.3645e-01, -3.1205e-01,  5.0736e-01, -5.4222e-01,\n",
       "         -1.3902e+00,  1.6529e-01, -1.8588e+00, -3.7066e-01,  8.8504e-01,\n",
       "         -1.3107e+00, -7.9268e-01, -1.8034e+00, -1.0636e+00, -5.3839e-01,\n",
       "          8.1914e-01,  2.2788e+00, -5.9037e-01, -9.3967e-01,  5.2291e-01,\n",
       "         -2.0588e-01, -1.0233e+00,  1.5311e+00,  3.7344e-01, -1.9259e+00,\n",
       "         -4.2263e-01, -1.0776e-01,  2.5869e-01, -2.6396e-01, -5.9133e-02,\n",
       "         -5.9949e-01, -9.5936e-01, -7.2709e-02,  3.5053e-01, -2.1919e-02,\n",
       "         -2.8692e-01,  6.1599e-01,  2.6053e+00,  1.4775e-03,  1.1240e+00,\n",
       "          4.4989e-01, -6.1923e-01, -2.0181e-01, -4.1818e-01,  5.5677e-01,\n",
       "         -8.3131e-01, -5.2412e-01, -1.7324e+00,  2.1409e-01, -9.9973e-01,\n",
       "          1.3769e+00,  4.5375e-01,  1.3476e+00,  1.7873e-02, -4.8439e-01,\n",
       "         -1.5305e+00, -3.2878e-01, -6.3516e-01,  8.1512e-01, -1.1252e+00,\n",
       "         -3.1094e-01,  1.8330e+00,  3.4821e-01, -1.4623e+00,  9.5274e-01,\n",
       "          1.1058e+00, -1.9274e+00,  9.1888e-01, -3.7459e-01, -3.8252e+00,\n",
       "         -1.9435e-01,  1.6752e-01,  1.7405e-01,  4.7651e-01,  4.9599e-02,\n",
       "         -1.6975e-01,  1.1904e-01,  3.7090e-01, -1.2353e+00, -1.1465e+00,\n",
       "         -5.5442e-01, -1.1874e+00,  1.1246e-01,  1.2339e+00, -5.2870e-02,\n",
       "         -7.4279e-02,  5.7411e-01, -2.4845e-01,  1.2659e-01, -5.2856e-01,\n",
       "          1.2189e+00,  8.5824e-02, -1.2796e+00,  2.2860e+00, -3.2039e-01,\n",
       "         -1.8188e-01,  5.7205e-01, -1.3190e+00, -3.4266e-01, -2.9073e-01,\n",
       "          6.3236e-01,  1.9453e+00, -2.4532e+00, -1.6307e-01, -1.7522e+00,\n",
       "         -4.2718e-02, -5.3026e-01,  5.0288e-01, -3.8899e-01, -1.2170e+00,\n",
       "         -7.7006e-03,  8.3001e-01,  1.6380e-02, -1.3899e+00, -1.0196e-01,\n",
       "         -1.6339e-01,  1.7573e+00,  4.7925e-01,  3.9752e-01,  5.0954e-01,\n",
       "         -1.2276e+00, -1.1205e+00,  3.3897e-01,  1.3092e-01,  3.2707e-01,\n",
       "          3.8370e-01, -9.0747e-01, -9.7960e-01,  5.8132e-01,  5.7411e-01,\n",
       "          9.6749e-01, -5.2411e-01,  2.8266e-01,  3.5412e-01,  2.1050e+00,\n",
       "          1.1563e-01,  6.8481e-01, -9.1111e-01, -8.3598e-01,  9.1447e-01,\n",
       "         -1.0562e+00, -2.1227e+00, -6.0856e-02, -4.6859e-02, -9.9366e-01,\n",
       "         -4.2585e-01, -1.1707e+00,  5.4926e-01,  4.4395e-01, -6.1376e-01,\n",
       "          2.4912e-01, -1.2242e+00,  3.0087e-02,  1.4514e+00, -9.4013e-01,\n",
       "          1.6158e-01, -3.6736e-01, -1.2707e+00,  2.2305e-01,  9.6565e-01,\n",
       "          7.5894e-01,  1.4878e+00,  1.8484e+00,  4.9437e-01,  3.0920e-01,\n",
       "         -1.4230e+00,  1.0957e-01,  2.5336e+00,  5.4089e-01,  1.2278e+00,\n",
       "          1.5858e+00, -8.1066e-01, -2.6259e-01,  6.5332e-01,  1.5528e-01,\n",
       "         -8.0889e-01, -1.0737e+00,  4.6978e-01,  4.9891e-02,  1.2626e+00,\n",
       "          1.5081e+00,  9.3038e-01, -1.4702e-01,  1.0028e+00, -5.5426e-01,\n",
       "         -1.5475e+00, -1.1919e+00, -8.4059e-01, -5.0754e-01, -7.0643e-01,\n",
       "          6.2545e-01,  1.2997e+00,  1.3694e+00,  2.3261e+00,  1.9314e-02,\n",
       "         -6.4821e-01, -2.8118e+00,  3.5240e-01,  2.2954e+00, -1.6753e+00,\n",
       "         -1.6056e+00, -3.4345e-01, -2.7517e-01, -1.2197e+00,  4.9474e-01,\n",
       "         -1.0116e-01, -1.0754e+00, -1.2936e-01, -1.1875e+00, -7.4799e-01,\n",
       "         -4.0517e-01, -8.0143e-01,  1.5214e+00,  3.5378e-01,  3.5245e-01,\n",
       "         -9.9087e-01, -9.7441e-01, -1.1204e+00,  4.3056e-01, -2.4838e+00,\n",
       "         -6.3583e-01,  6.3478e-01, -1.7609e+00,  8.9802e-01, -1.0949e+00,\n",
       "          1.8149e-01, -1.3549e-02, -3.4903e-04,  1.3414e+00, -2.8669e-01,\n",
       "          9.9146e-01,  3.3844e-01,  2.2987e-02,  1.5016e+00, -7.0282e-01,\n",
       "          2.2787e-01, -1.4419e+00, -1.3007e+00, -6.8061e-01,  6.6992e-01]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(lm_embeddings[0], img_embeddings[0], mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bashlab_cogenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
