{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import timeit\n",
    "from collections import defaultdict\n",
    "import traceback\n",
    "\n",
    "from cognitive.auto_task.arguments import get_args\n",
    "from cognitive import task_generator as tg\n",
    "from cognitive import constants as const\n",
    "from cognitive import stim_generator as sg\n",
    "from cognitive import info_generator as ig\n",
    "from cognitive.auto_task.auto_task_util import *\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "\n",
    "from typing import Tuple, Union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    args = get_args()\n",
    "    print(args)\n",
    "\n",
    "    const.DATA = const.Data(dir_path=args.stim_dir)\n",
    "\n",
    "    task_dir = args.task_dir\n",
    "\n",
    "    if task_dir:\n",
    "        if not os.path.isdir(task_dir):\n",
    "            raise ValueError('Task Directory not found')\n",
    "        start = timeit.default_timer()\n",
    "        task_folders = [f.path for f in os.scandir(task_dir) if f.is_dir()]\n",
    "        for f in task_folders:\n",
    "            try:\n",
    "                # uncomment to reconstruct the graph\n",
    "                # labels, adj = os.path.join(f, 'node_labels'), os.path.join(f, 'adj_dict')\n",
    "                # with open(labels, 'rb') as h:\n",
    "                #     labels = json.load(h)\n",
    "                # with open(adj, 'rb') as h:\n",
    "                #     adj = json.load(h)\n",
    "                # g = nx.from_dict_of_dicts(adj, create_using=nx.DiGraph)\n",
    "                # g = nx.relabel_nodes(g, labels)\n",
    "                # print(sorted(g))\n",
    "                task_json_fp = os.path.join(f, 'temporal_task.json')\n",
    "                with open(task_json_fp, 'rb') as h:\n",
    "                    task_dict = json.load(h)\n",
    "                task_dict['operator'] = tg.load_operator_json(task_dict['operator'])\n",
    "                temporal_task = tg.TemporalTask(\n",
    "                    operator=task_dict['operator'],\n",
    "                    n_frames=task_dict['n_frames'],\n",
    "                    first_shareable=task_dict['first_shareable'],\n",
    "                    whens=task_dict['whens']\n",
    "                )\n",
    "                for i in range(args.n_trials):\n",
    "                    instance_fp = os.path.join(f, f'trial_{i}')\n",
    "                    if os.path.exists(instance_fp):\n",
    "                        shutil.rmtree(instance_fp)\n",
    "                    os.makedirs(instance_fp)\n",
    "\n",
    "                    write_trial_instance(temporal_task, instance_fp, args.img_size, args.fixation_cue)\n",
    "            except Exception as e:\n",
    "                traceback.print_exc()\n",
    "        stop = timeit.default_timer()\n",
    "        print('Time taken to generate trials: ', stop - start)\n",
    "    else:\n",
    "        start = timeit.default_timer()\n",
    "        # TODO: check for duplicated tasks by comparing task graphs\n",
    "        for i in range(args.n_tasks):\n",
    "            # make directory for saving task information\n",
    "            fp = os.path.join(args.output_dir, str(i))\n",
    "            if os.path.exists(fp):\n",
    "                shutil.rmtree(fp)\n",
    "            os.makedirs(fp)\n",
    "\n",
    "            count = 0\n",
    "            # generate a subtask graph and actual task\n",
    "            subtask_graph = subtask_graph_generator(count=count, max_op=args.max_op, max_depth=args.max_depth,\n",
    "                                                    select_limit=args.select_limit)\n",
    "            subtask = tg.subtask_generation(subtask_graph)\n",
    "            count = subtask_graph[2] + 1\n",
    "            for _ in range(args.max_switch):\n",
    "                if random.random() < args.switch_threshold:  # if add switch\n",
    "                    new_task_graph = subtask_graph_generator(count=count, max_op=args.max_op, max_depth=args.max_depth,\n",
    "                                                             select_limit=args.select_limit)\n",
    "                    count = new_task_graph[2] + 1\n",
    "\n",
    "                    conditional = subtask_graph_generator(count=count, max_op=args.max_op, max_depth=args.max_depth,\n",
    "                                                          select_limit=args.select_limit,\n",
    "                                                          root_op=random.choice(boolean_ops))\n",
    "                    conditional_task = tg.subtask_generation(conditional)\n",
    "                    count = conditional[2] + 1\n",
    "                    if random.random() < 0.5:\n",
    "                        do_if = subtask_graph\n",
    "                        do_if_task = subtask\n",
    "                        do_else = new_task_graph\n",
    "                        do_else_task = tg.subtask_generation(do_else)\n",
    "                    else:\n",
    "                        do_if = new_task_graph\n",
    "                        do_if_task = tg.subtask_generation(do_if)\n",
    "                        do_else = subtask_graph\n",
    "                        do_else_task = subtask\n",
    "                    subtask_graph = switch_generator(conditional, do_if, do_else)\n",
    "                    count = subtask_graph[2] + 1\n",
    "                    subtask = tg.switch_generation(conditional_task, do_if_task, do_else_task)\n",
    "            # TODO: some guess objset error where ValueError occurs\n",
    "            # write_instance(subtask_graph, subtask, fp, args.img_size, args.n_trials)\n",
    "            write_task_instance(subtask_graph, subtask, fp)\n",
    "        stop = timeit.default_timer()\n",
    "        print('Time taken to generate tasks: ', stop - start)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bashlab_cogenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
