{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Task Generation\n",
    "- Here we generate each task randomly for every training iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training configurations\n",
    "epochs = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = torch.optim.Adam(\n",
    "    (p for p in model.parameters() if p.requires_grad), lr=lr\n",
    ")\n",
    "\n",
    "mask = generate_causal_mask(MAX_FRAMES).to(device)\n",
    "\n",
    "# torch.manual_seed(0)\n",
    "# Generates a random location comparison task\n",
    "def gen_comp_loc(lm_embedder, img_embedder):\n",
    "    # f1 = random.randint(0, 4)\n",
    "    # f2 = random.randint(f1+1,5)\n",
    "\n",
    "    # task = CompareLocTemporal(whens=['last'+str(f1),'last'+str(f2)])\n",
    "\n",
    "    task = CompareLocTemporal(whens=['last0','last1'])\n",
    "\n",
    "    frame_info = ig.FrameInfo(task, task.generate_objset())\n",
    "    compo_info = ig.TaskInfoCompo(task, frame_info)\n",
    "    objset = compo_info.frame_info.objset\n",
    "\n",
    "    frames = []\n",
    "    for i, (epoch, frame) in enumerate(zip(sg.render(objset, 224), compo_info.frame_info)):\n",
    "        if not any('ending' in description for description in frame.description):\n",
    "            sg.add_fixation_cue(epoch)\n",
    "        img = np.rollaxis(np.array(Image.fromarray(epoch, 'RGB'), dtype=np.float32),2,0)\n",
    "        frames.append(img)\n",
    "\n",
    "    frames = torch.tensor(frames)\n",
    "\n",
    "    frames = img_embedder(frames, vit_encoder).unsqueeze(0)\n",
    "\n",
    "    _, compo_example, _ = compo_info.get_examples()\n",
    "\n",
    "    instruction = compo_example['instruction']\n",
    "\n",
    "    instruction = tokenizer(instruction, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    instruction = lm_embedder(instruction, lm_encoder).unsqueeze(0)\n",
    "\n",
    "    actions = compo_example['answers']\n",
    "\n",
    "    action_map = {'true': 0, 'false': 1, 'null': 2}\n",
    "\n",
    "    target_actions = []\n",
    "    for action in actions:\n",
    "        target_actions.append(action_map[action])\n",
    "\n",
    "    return instruction, frames, torch.tensor(target_actions, dtype=torch.float32).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation loop using random generation\n",
    "\n",
    "n_tasks = 0\n",
    "\n",
    "# Store the average loss after each epoch\n",
    "all_loss = {'train_loss':[], 'val_loss':[]}\n",
    "all_acc = {'train_acc':[], 'val_acc':[]}\n",
    "\n",
    "print(\"starting\")\n",
    "for epoch in range(epochs):\n",
    "    print(f\"epoch={epoch}\")\n",
    "\n",
    "    # Epoch stat trackers\n",
    "    epoch_loss = 0\n",
    "    epoch_correct = 0\n",
    "    epoch_count = 0\n",
    "\n",
    "    for i in range(n_tasks):\n",
    "\n",
    "        # Inputs and Targets\n",
    "        instruction, frames, targets = gen_comp_loc(lm_embedder, img_embedder)\n",
    "\n",
    "        # print(frames.shape)\n",
    "        # print(instruction.shape)\n",
    "        # print(len(targets))\n",
    "\n",
    "        # Frame Padding\n",
    "        padding_mask = generate_pad_mask(batch=frames)\n",
    "        pad_indexes = np.argwhere(np.array(padding_mask) == False)[:,1]\n",
    "\n",
    "        # Get predictions\n",
    "        predictions = model(instruction, frames, mask, padding_mask)\n",
    "        predictions = predictions[:,pad_indexes]\n",
    "\n",
    "        print(predictions.shape)\n",
    "        print(predictions.permute(0, 2, 1).shape)\n",
    "        print(targets.shape)\n",
    "\n",
    "        # Get Loss by permuting the predictions into correct shape (batch_size, n_classes, seq_len)\n",
    "        loss = criterion(predictions.permute(0, 2, 1), targets.long())\n",
    "\n",
    "        # Track stats\n",
    "        # torch.nn.functional.softmax(input, dim=None, _stacklevel=3, dtype=None)\n",
    "        correct = predictions.argmax(dim=-1) == targets\n",
    "        acc = correct.sum().item() / correct.size(0)\n",
    "        epoch_correct += correct.sum().item()\n",
    "        epoch_count += correct.size(0)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validate on validation set every 5 epochs\n",
    "    if (epoch+1) % 2 == 0:\n",
    "        # Turn off gradient calcs\n",
    "        with torch.no_grad():\n",
    "            val_epoch_loss = 0\n",
    "            val_epoch_correct = 0\n",
    "            val_epoch_count = 0\n",
    "\n",
    "            for idx, batch in enumerate(iter(val_dataloader)):\n",
    "                # Inputs and Targets\n",
    "                instruction = batch['instruction']\n",
    "                frames = batch['frames']\n",
    "                targets = batch['actions']\n",
    "                \n",
    "                # Frame Padding\n",
    "                padding_mask = generate_pad_mask(batch=frames)\n",
    "                pad_indexes = np.argwhere(np.array(padding_mask) == False)[:,1]\n",
    "\n",
    "                # Get predictions\n",
    "                predictions = model(instruction, frames, mask, padding_mask)\n",
    "                predictions = predictions[:,pad_indexes]\n",
    "\n",
    "                # Get Loss\n",
    "                loss = criterion(predictions.permute(0, 2, 1), targets.long())\n",
    "\n",
    "                correct = predictions.argmax(dim=-1) == targets\n",
    "                acc = correct.sum().item() / correct.size(0)\n",
    "\n",
    "                val_epoch_correct += correct.sum().item()\n",
    "                val_epoch_count += correct.size(0)\n",
    "                val_epoch_loss += loss.item()\n",
    "\n",
    "        # Track loss and acc ever 5 epochs\n",
    "        avg_train_loss = epoch_loss / len(train_dataloader)\n",
    "        avg_val_loss = val_epoch_loss / len(val_dataloader)\n",
    "\n",
    "\n",
    "        all_loss['val_loss'].append(avg_val_loss)\n",
    "        all_acc['val_acc'].append(val_epoch_correct / val_epoch_count)\n",
    "\n",
    "        all_acc['train_acc'].append(epoch_correct / epoch_count)\n",
    "        all_loss['train_loss'].append(avg_train_loss)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
